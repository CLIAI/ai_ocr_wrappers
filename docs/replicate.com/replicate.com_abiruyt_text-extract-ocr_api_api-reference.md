Title: abiruyt/text-extract-ocr – Replicate

URL Source: https://replicate.com/abiruyt/text-extract-ocr/api/api-reference

Markdown Content:
abiruyt/text-extract-ocr – API reference
===============


## When you use Replicate Python library with abiruyt/text-extract-ocr – API reference

## Create a prediction

predictions.create

Headers

- Preferstring
    
    Leave the request open and wait for the model to finish generating output. Set to `wait=n` where n is a number of seconds between 1 and 60.
    
    See https://replicate.com/docs/topics/predictions/create-a-prediction#sync-mode for more information.
    
    Show more
    

Request body

- inputobjectRequired
    
    The model's input as a JSON object. The input schema depends on what model you are running. To see the available inputs, click the "API" tab on the model you are running or [get the model version](https://replicate.com/abiruyt/text-extract-ocr/api/api-reference#models.versions.get) and look at its `openapi_schema` property. For example, [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) takes `prompt` as an input.
    
    Files should be passed as HTTP URLs or data URLs.
    
- versionstringRequired
    
    The ID of the model version that you want to run.
    
- webhookstring
    
    An HTTPS URL for receiving a webhook when the prediction has new output. The webhook will be a POST request where the request body is the same as the response body of the [get prediction](https://replicate.com/abiruyt/text-extract-ocr/api/api-reference#predictions.get) operation. If there are network problems, we will retry the webhook a few times, so make sure it can be safely called more than once. Replicate will not follow redirects when sending webhook requests to your service, so be sure to specify a URL that will resolve without redirecting.
    
    Show more
    
- webhook\_events\_filterarray
    
    By default, we will send requests to your webhook URL whenever there are new outputs or the prediction has finished. You can change which events trigger webhook requests by specifying `webhook_events_filter` in the prediction request:
    
    - `start`: immediately on prediction start
    - `output`: each time a prediction generates an output (note that predictions can generate multiple outputs)
    - `logs`: each time log output is generated by a prediction
    - `completed`: when the prediction reaches a terminal state (succeeded/canceled/failed)
    
    For example, if you only wanted requests to be sent at the start and end of the prediction, you would provide:
    
    ```json
    {
      "version": "5c7d5dc6dd8bf75c1acaa8565735e7986bc5b66206b55cca93cb72c9bf15ccaa",
      "input": {
        "text": "Alice"
      },
      "webhook": "https://example.com/my-webhook",
      "webhook_events_filter": ["start", "completed"]
    }
    ```
    
    Requests for event types `output` and `logs` will be sent at most once every 500ms. If you request `start` and `completed` webhooks, then they'll always be sent regardless of throttling.
    
    Show more
    

## Create a prediction and get the output

```python
import replicate

input = {
    "image": "https://replicate.delivery/pbxt/KhTOXyqrFtkoj2hobh1a4As6dYDIvNV2Ujbc0LbGD9ZguRwR/bowers.jpg"
}

output = replicate.run(
    "abiruyt/text-extract-ocr:a524caeaa23495bc9edc805ab08ab5fe943afd3febed884a4f3747aa32e9cd61",
    input=input
)
print(output)
#=> "The Life and Work of\nFredson Bowers\n\nby\nG. THOMAS TA...
```

## Create prediction with webook

Create a prediction

predictions.create

Headers

- Preferstring
    
    Leave the request open and wait for the model to finish generating output. Set to `wait=n` where n is a number of seconds between 1 and 60.
    
    See https://replicate.com/docs/topics/predictions/create-a-prediction#sync-mode for more information.
    
    Show more
    

Request body

- inputobjectRequired
    
    The model's input as a JSON object. The input schema depends on what model you are running. To see the available inputs, click the "API" tab on the model you are running or [get the model version](https://replicate.com/abiruyt/text-extract-ocr/api/api-reference#models.versions.get) and look at its `openapi_schema` property. For example, [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) takes `prompt` as an input.
    
    Files should be passed as HTTP URLs or data URLs.
    
    Use an HTTP URL when:
    
    - you have a large file > 256kb
    - you want to be able to use the file multiple times
    - you want your prediction metadata to be associable with your input files
    
    Use a data URL when:
    
    - you have a small file <= 256kb
    - you don't want to upload and host the file somewhere
    - you don't need to use the file again (Replicate will not store it)
    
    Show more
    
- versionstringRequired
    
    The ID of the model version that you want to run.
    
- webhookstring
    
    An HTTPS URL for receiving a webhook when the prediction has new output. The webhook will be a POST request where the request body is the same as the response body of the [get prediction](https://replicate.com/abiruyt/text-extract-ocr/api/api-reference#predictions.get) operation. If there are network problems, we will retry the webhook a few times, so make sure it can be safely called more than once. Replicate will not follow redirects when sending webhook requests to your service, so be sure to specify a URL that will resolve without redirecting.
    
    Show more
    
- webhook\_events\_filterarray
    
    By default, we will send requests to your webhook URL whenever there are new outputs or the prediction has finished. You can change which events trigger webhook requests by specifying `webhook_events_filter` in the prediction request:
    
    - `start`: immediately on prediction start
    - `output`: each time a prediction generates an output (note that predictions can generate multiple outputs)
    - `logs`: each time log output is generated by a prediction
    - `completed`: when the prediction reaches a terminal state (succeeded/canceled/failed)
    
    For example, if you only wanted requests to be sent at the start and end of the prediction, you would provide:
    
    ```json
    {
      "version": "5c7d5dc6dd8bf75c1acaa8565735e7986bc5b66206b55cca93cb72c9bf15ccaa",
      "input": {
        "text": "Alice"
      },
      "webhook": "https://example.com/my-webhook",
      "webhook_events_filter": ["start", "completed"]
    }
    ```
    
    Requests for event types `output` and `logs` will be sent at most once every 500ms. If you request `start` and `completed` webhooks, then they'll always be sent regardless of throttling.
    
    Show more
    

Examples

Create

Create a prediction and get the output

Webhooks

Create a new prediction using webhooks

Make a request

post/predictions

```python
import replicate

input = {
    "image": "https://replicate.delivery/pbxt/KhTOXyqrFtkoj2hobh1a4As6dYDIvNV2Ujbc0LbGD9ZguRwR/bowers.jpg"
}

callback_url = "https://my.app/webhooks/replicate"
replicate.predictions.create(
    version="a524caeaa23495bc9edc805ab08ab5fe943afd3febed884a4f3747aa32e9cd61",
    input=input,
    webhook=callback_url,
    webhook_events_filter=["completed"]
)

# The server will now handle the event and log:
#=> Prediction(id='z3wbih3bs64of7lmykbk7tsdf4', ...)
```


## Get a prediction

predictions.get

Input parameters

- prediction\_idstringRequired
    
    The ID of the prediction to get.
    

Examples

Get

Get the latest version of a prediction by id

Make a request

get/predictions/{prediction\_id}

```python
import replicate

prediction = replicate.predictions.get(prediction_id)
print(prediction)
#=> Prediction(id="xyz...", status="successful", ... )
```


## Cancel a prediction

predictions.cancel

Input parameters

- prediction\_idstringRequired
    
    The ID of the prediction to cancel.
    

Examples

Cancel

Cancel an in progress prediction

Make a request

post/predictions/{prediction\_id}/cancel

```python
import replicate

prediction = replicate.predictions.get(prediction_id)
prediction.cancel()
print(prediction)
#=> Prediction(id="xyz...", status="canceled", ... )
```

## List predictions

predictions.list

Examples

List

List the first page of your predictions

Paginate

Iterate through all your predictions

Make a request

get/predictions

```python
import replicate

predictions = replicate.predictions.list()
print(predictions.results)
#=> [Prediction(id="xyz...", status="successful", ... ), Prediction(id="abc...", status="successful", ... )]
```
